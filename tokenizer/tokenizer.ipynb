{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.splitter import sentence_splitter\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import wordpunct_tokenize, word_tokenize, TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hati-hati', ',', 'ji-as', 'kk-ds', '.', 'baju', '.', '3x', '1,9', '12.45', '3-4', 'asda-asd', '!', 'satu', '+', 'dua']\n",
      "['hati-hati', ',', 'ji-as', 'kk-ds', '.', 'baju', '.', '3x', '1,9', '12.45', '3-4', 'asda-asd', '!', 'satu+dua']\n",
      "['hati', '-', 'hati', ',', 'ji', '-', 'as', 'kk', '-', 'ds', '.', 'baju', '.', '3x', '1', ',', '9', '12', '.', '45', '3', '-', '4', 'asda', '-', 'asd', '!', 'satu', '+', 'dua']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "#sentence = \"~kk RT @GoddesofKebab lgüò≠üò≠üò≠ 500rbüò≠ü§≤üèª 10juta bapak.aku internet! -ok temen\\\"ku refund-nya baik-baik baik/buruk nge-print (ads) (rumah kita) era 4.0 ngasih? tender :)) proyek, I'm Bob's I'll apps ovo...ke vendor abal2. #mantapkali https://towardsdatascience.com/pos-tagging-using-crfs-ea430c5fb78b\"\n",
    "#stc = ' Wis \\'lah...tidur satu\\' \"Gw dapet bedanya‚Äù ibu\" 500rbüò≠ü§≤üèª ‚Äúhalah tinggal, ngeprint. sendiri apa bedanya‚Äù terburu-buru tok..hahaha 2.3 !ok iki..haha mari...\" .ki...,, ovo...ke vendor abal2. 10% 10juta siang/malam bapak2 &ok makan.minum bener¬≤ ibu\\\" -__-  (¬¥ÔΩ•œâÔΩ•`) he!! apa??? and -_- SIRAMPOG .mari...\\\" 14.07.2021 #instaNews Senin 14-07-2021 21/10/19 [telah] {terjadi} +angin kencang, di-print termasuk Sirampog. Kondisi (terkini) Sirampog, @100.000 aik-aik 12+ .. *info *tunggu* update dari ?kita ya! lur .. Do\\'a kan yg‚Ä¶  https://t.co/7Dl8UV2QZU'\n",
    "#stc = '\":v :V ;v lgüò≠üò≠üò≠ 500rbüò≠ü§≤üèª  -_- -__- dapet bola aja jarang! Susah! Sekalinya dapet, pelanggaran! MAU KAMU APAA??\" ‚Äúhalah tinggal ngeprint sendiri apa bedanya‚Äù ü§£ü§£ü§£ü§£ lemot \"@kecepoood: XL labil donlod munggah mudun üò©\"'\n",
    "#stc = '(¬¥ÔΩ•œâÔΩ•`) \\(^‚ñø^)/ bener¬≤ baju\\'e I\\'m ‚Äúhalah may*ora df~~~ ~~~fsf tinggal, iki..haha !dfs &sdf !fsd mari. dsfg, ,sdf .ki ...,, ovo...ke (sendiri) (sdf aja) ngeprint. apa bedanya‚Äù  ~ff -fg sdf~ sfs- 4.3 iki..haha !dfs &sdf !fsd mari. dsfg, ,sdf .ki ...,, ovo...ke (sendiri) (sdf aja) $10 Rp10.000,00 11-23-22 12/12/32 15.00 @10.1000 #sdfs @sfsdf https://pynative.com/python-regex-compile/  -= STASIUN CITAYAM =- \" @sdfsd: beda :\\\") ;)) ü§£ü§£ü§£ü§£'\n",
    "sentence = 'hati-hati, ji-as kk-ds. baju. 3x 1,9 12.45 3-4 asda-asd! satu+dua'\n",
    "print(sentence_splitter(sentence))\n",
    "print(word_tokenize(sentence))\n",
    "print(wordpunct_tokenize(sentence))\n",
    "#sentence.split()\n",
    "#stc.split()\n",
    "\n",
    "#PR: 1-3 not tokenized correctly, asda-asdasd, sddfs+sdfds,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_file = '../dataset/new-tagged-500.tsv'\n",
    "#source_file = '../dataset/filtered-tweet-500.xlsx'\n",
    "#target_file = '../dataset/new-tagged-300.tsv'\n",
    "#source_file = '../dataset/data-150322.xlsx'\n",
    "#target_file = '../dataset/new-tagged-1000.tsv'\n",
    "#source_file = '../dataset/data-210322.xlsx'\n",
    "target_file = '../raw dataset/all-tagged-test-600.tsv'\n",
    "source_file = '../raw dataset/data-260322.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(source_file)\n",
    "tweets = all_data['tweet'].head(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data = pd.read_excel(source_file, header=None)\n",
    "#tweets = all_data[0]\n",
    "#len(all_data)\n",
    "#tweets = all_data['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "600"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indonesian dictionary\n",
    "id_dict_file = pd.read_csv('../dict/indonesian_words_final.csv')\n",
    "id_dict = id_dict_file.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# named entity dictionary\n",
    "ne_dict = pd.read_csv('../dict/NE-list.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Javanese dictionary\n",
    "jv_dict_file = pd.read_csv('../dict/unknown_words_java.csv')\n",
    "jv_dict = jv_dict_file.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English dictionary\n",
    "en_dict_file = pd.read_csv('../dict/english_words_final.csv')\n",
    "en_dict = en_dict_file.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix ID-EN dictionary\n",
    "mix_id_en_file = pd.read_csv('../dict/mixed_words_final.csv')\n",
    "mix_id_en_dict = mix_id_en_file.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix JV-EN dictionary\n",
    "mix_jv_en_dict = pd.read_csv('../dict/jv-en.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix ID-JV dictionary\n",
    "mix_id_jv_dict = pd.read_csv('../dict/id-jv.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger(target_file, input_data):\n",
    "\ttweets = input_data\n",
    "\twith open(target_file, 'a') as f:\n",
    "\t\tfor tw in tweets:\n",
    "\t\t\ttokens = sentence_splitter(tw)\n",
    "\t\t\tfor token in tokens:\n",
    "\t\t\t\ttlower = token.lower()\n",
    "\t\t\t\tif token.startswith('#') or token.startswith('@') or token.endswith('%') or token.isnumeric():\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'O' + '\\n')\n",
    "\t\t\t\telif re.match(r'https?:\\/\\/.*[\\r\\n]*',token) or re.match(r'[\\W]', token):\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'O' + '\\n')\n",
    "\t\t\t\telif tlower in ne_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'NE' + '\\n')\n",
    "\t\t\t\telif tlower in id_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'ID' + '\\n')\n",
    "\t\t\t\telif tlower in en_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'EN' + '\\n')\n",
    "\t\t\t\telif tlower in jv_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'JV' + '\\n')\n",
    "\t\t\t\telif tlower in mix_id_en_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'MIX-ID-EN' + '\\n')\n",
    "\t\t\t\telif tlower in mix_id_jv_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'MIX-ID-JV' + '\\n')\n",
    "\t\t\t\telif tlower in mix_jv_en_dict.values:\n",
    "\t\t\t\t\tf.write(token + '\\t' + 'MIX-JV-EN' + '\\n')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tf.write(token + '\\t' + '\\n')\n",
    "\t\t\tf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger(target_file=target_file, input_data=tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}